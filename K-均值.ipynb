{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def loadDataSet(fileName):  # 解析文件,得到一个浮点数字类型的矩阵\n",
    "    dataMat = []              # 文件的最后一个字段是类别标签\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split()\n",
    "        #fltLine = map(float, curLine)    # 将每个元素转成float类型\n",
    "        fltLine = list(map(float, curLine))\n",
    "        dataMat.append(fltLine)\n",
    "    fr.close()\n",
    "    return dataMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算欧几里得距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2))) # 求两个向量之间的距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建聚簇中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1]\n",
    "    centroids = mat(zeros((k,n)))   # 每个质心有n个坐标值，总共要k个质心\n",
    "    for j in range(n):\n",
    "        minJ = min(dataSet[:,j])\n",
    "        maxJ = max(dataSet[:,j])\n",
    "        rangeJ = float(maxJ - minJ)\n",
    "        centroids[:,j] = minJ + rangeJ * random.rand(k, 1)\n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# k-means 聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(dataSet, k, distMeans =distEclud, createCent = randCent):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2)))    # 用于存放该样本属于哪类及质心距离\n",
    "    # clusterAssment第一列存放该数据所属的中心点，第二列是该数据到中心点的距离\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True   # 用来判断聚类是否已经收敛\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False;\n",
    "        for i in range(m):  # 把每一个数据点划分到离它最近的中心点\n",
    "            minDist = inf; minIndex = -1;\n",
    "            for j in range(k):\n",
    "                distJI = distMeans(centroids[j,:], dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j  # 如果第i个数据点到第j个中心点更近，则将i归属为j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True;  # 如果分配发生变化，则需要继续迭代\n",
    "            clusterAssment[i,:] = minIndex,minDist**2   # 并将第i个数据点的分配情况存入字典\n",
    "        print(centroids)\n",
    "        for cent in range(k):   # 重新计算中心点\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0].A == cent)[0]]   # 去第一列等于cent的所有列\n",
    "            centroids[cent,:] = mean(ptsInClust, axis = 0)  # 算出这些数据的中心点\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.16006774  0.60735391]\n",
      " [-3.93044626  4.07485206]\n",
      " [-3.18671118 -2.23742529]\n",
      " [ 3.33746025 -3.2689781 ]]\n",
      "[[ 1.7658705   1.990256  ]\n",
      " [-2.72438167  3.26469   ]\n",
      " [-3.90433975 -2.144565  ]\n",
      " [ 2.82987583 -2.37999483]]\n",
      "[[ 2.611752    1.70956283]\n",
      " [-2.2408245   3.2843035 ]\n",
      " [-3.90433975 -2.144565  ]\n",
      " [ 2.5388238  -3.1877908 ]]\n",
      "[[ 2.611752    1.70956283]\n",
      " [-2.2408245   3.2843035 ]\n",
      " [-3.90433975 -2.144565  ]\n",
      " [ 2.5388238  -3.1877908 ]]\n",
      "[[0.         2.80277213]\n",
      " [1.         1.49064034]\n",
      " [1.         3.60094455]\n",
      " [2.         3.65912744]\n",
      " [0.         4.16200382]\n",
      " [1.         4.83311081]\n",
      " [3.         4.37371398]\n",
      " [2.         0.35059657]\n",
      " [0.         0.01641067]\n",
      " [3.         0.42649256]\n",
      " [3.         1.05215123]\n",
      " [2.         2.16043443]\n",
      " [0.         4.17515847]\n",
      " [3.         1.29671628]\n",
      " [0.         8.43067135]\n",
      " [2.         3.07371143]\n",
      " [0.         0.06673501]\n",
      " [1.         2.10791001]\n",
      " [3.         0.19241673]]\n"
     ]
    }
   ],
   "source": [
    "datMat = mat(loadDataSet('dataset4.txt'))\n",
    "myCentroids,clustAssing = kMeans(datMat,4)\n",
    "print (myCentroids)\n",
    "print (clustAssing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
